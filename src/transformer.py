"""
å®Œæ•´çš„ Transformer æ¨¡å‹å®ç°

ç»“æ„ï¼š
    è¾“å…¥ -> Embedding + ä½ç½®ç¼–ç  -> Encoder -> Decoder -> è¾“å‡ºå±‚
"""

import torch
import torch.nn as nn
import matplotlib.pyplot as plt
from .encoder import Encoder
from .decoder import Decoder, generate_causal_mask
from .components import PositionalEncoding

# é…ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'STHeiti', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False


class Transformer(nn.Module):
    """å®Œæ•´çš„ Transformer æ¨¡å‹"""
    
    def __init__(
        self,
        src_vocab_size,
        tgt_vocab_size,
        d_model=512,
        num_heads=8,
        num_encoder_layers=6,
        num_decoder_layers=6,
        d_ff=2048,
        max_seq_len=5000,
        dropout=0.1,
        pad_idx=0
    ):
        """
        Args:
            src_vocab_size: æºè¯­è¨€è¯æ±‡è¡¨å¤§å°
            tgt_vocab_size: ç›®æ ‡è¯­è¨€è¯æ±‡è¡¨å¤§å°
            d_model: æ¨¡å‹ç»´åº¦
            num_heads: æ³¨æ„åŠ›å¤´æ•°
            num_encoder_layers: Encoder å±‚æ•°
            num_decoder_layers: Decoder å±‚æ•°
            d_ff: å‰é¦ˆç½‘ç»œéšè—å±‚ç»´åº¦
            max_seq_len: æœ€å¤§åºåˆ—é•¿åº¦
            dropout: dropout æ¯”ç‡
            pad_idx: paddingç´¢å¼•ï¼ˆé»˜è®¤0ï¼‰
        """
        super(Transformer, self).__init__()
        
        self.d_model = d_model
        self.pad_idx = pad_idx  # ä¿å­˜pad_idxä¾›generateä½¿ç”¨
        
        # æºåºåˆ—å’Œç›®æ ‡åºåˆ—çš„ Embedding å±‚ï¼ˆè®¾ç½®padding_idxï¼‰
        # padding_idxå¤„çš„embeddingå‘é‡ä¸ä¼šè¢«æ›´æ–°ï¼Œä¸”ä¼šè¢«è‡ªåŠ¨æ¸…é›¶
        self.src_embedding = nn.Embedding(src_vocab_size, d_model, padding_idx=pad_idx)
        self.tgt_embedding = nn.Embedding(tgt_vocab_size, d_model, padding_idx=pad_idx)
        
        # ä½ç½®ç¼–ç 
        self.positional_encoding = PositionalEncoding(d_model, max_seq_len, dropout)
        
        # Encoder å’Œ Decoder
        self.encoder = Encoder(num_encoder_layers, d_model, num_heads, d_ff, dropout)
        self.decoder = Decoder(num_decoder_layers, d_model, num_heads, d_ff, dropout)
        
        # è¾“å‡ºæŠ•å½±å±‚
        self.output_projection = nn.Linear(d_model, tgt_vocab_size)
        
        # åˆå§‹åŒ–å‚æ•°
        self._init_parameters()
    
    def _init_parameters(self):
        """
        æ”¹è¿›çš„å‚æ•°åˆå§‹åŒ–ç­–ç•¥
        å‚è€ƒ: "Attention Is All You Need" å’Œåç»­æœ€ä½³å®è·µ
        """
        for name, p in self.named_parameters():
            if p.dim() > 1:
                # å¯¹äºçº¿æ€§å±‚å’Œembeddingï¼Œä½¿ç”¨xavieråˆå§‹åŒ–
                if 'embedding' in name:
                    nn.init.normal_(p, mean=0, std=self.d_model ** -0.5)
                elif 'weight' in name:
                    nn.init.xavier_uniform_(p)
            # LayerNormå‚æ•°ä¿æŒé»˜è®¤åˆå§‹åŒ–(gamma=1, beta=0)
    
    def encode(self, src, src_mask=None):
        """
        Encoder å‰å‘ä¼ æ’­
        Args:
            src: æºåºåˆ— [batch_size, src_len]
            src_mask: æºåºåˆ—æ©ç 
        Returns:
            Encoder è¾“å‡º [batch_size, src_len, d_model]
        """
        # Embedding + ä½ç½®ç¼–ç 
        src_emb = self.src_embedding(src) * (self.d_model ** 0.5)
        src_emb = self.positional_encoding(src_emb)
        
        # é€šè¿‡ Encoder
        encoder_output = self.encoder(src_emb, src_mask)
        
        return encoder_output
    
    def decode(self, tgt, encoder_output, src_mask=None, tgt_mask=None):
        """
        Decoder å‰å‘ä¼ æ’­
        Args:
            tgt: ç›®æ ‡åºåˆ— [batch_size, tgt_len]
            encoder_output: Encoder è¾“å‡º
            src_mask: æºåºåˆ—æ©ç 
            tgt_mask: ç›®æ ‡åºåˆ—æ©ç ï¼ˆå› æœæ©ç ï¼‰
        Returns:
            Decoder è¾“å‡º [batch_size, tgt_len, d_model]
        """
        # Embedding + ä½ç½®ç¼–ç 
        tgt_emb = self.tgt_embedding(tgt) * (self.d_model ** 0.5)
        tgt_emb = self.positional_encoding(tgt_emb)
        
        # é€šè¿‡ Decoder
        decoder_output = self.decoder(tgt_emb, encoder_output, src_mask, tgt_mask)
        
        return decoder_output
    
    def forward(self, src, tgt, src_mask=None, tgt_mask=None):
        """
        å®Œæ•´çš„å‰å‘ä¼ æ’­
        Args:
            src: æºåºåˆ— [batch_size, src_len]
            tgt: ç›®æ ‡åºåˆ— [batch_size, tgt_len]
            src_mask: æºåºåˆ—æ©ç 
            tgt_mask: ç›®æ ‡åºåˆ—æ©ç 
        Returns:
            è¾“å‡º logits [batch_size, tgt_len, tgt_vocab_size]
        """
        # Encode
        encoder_output = self.encode(src, src_mask)
        
        # Decode
        decoder_output = self.decode(tgt, encoder_output, src_mask, tgt_mask)
        
        # è¾“å‡ºæŠ•å½±
        output = self.output_projection(decoder_output)
        
        return output
    
    def generate(self, src, max_len=50, start_token=1, end_token=2):
        """
        è‡ªå›å½’ç”Ÿæˆï¼ˆè´ªå¿ƒè§£ç ï¼‰
        Args:
            src: æºåºåˆ— [batch_size, src_len]
            max_len: æœ€å¤§ç”Ÿæˆé•¿åº¦
            start_token: å¼€å§‹æ ‡è®°
            end_token: ç»“æŸæ ‡è®°
        Returns:
            ç”Ÿæˆçš„åºåˆ— [batch_size, gen_len]
        """
        self.eval()
        batch_size = src.size(0)
        device = src.device
        
        # ğŸ”§ ä¿®å¤BUG: åˆ›å»ºsrc_maskä»¥å¿½ç•¥paddingï¼ˆä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
        # src_mask: [batch_size, 1, 1, src_len]
        src_mask = (src != self.pad_idx).unsqueeze(1).unsqueeze(2)
        
        # Encode æºåºåˆ—ï¼ˆä¼ é€’src_maskï¼‰
        encoder_output = self.encode(src, src_mask)
        
        # åˆå§‹åŒ–ç›®æ ‡åºåˆ—ï¼ˆåªæœ‰å¼€å§‹æ ‡è®°ï¼‰
        tgt = torch.full((batch_size, 1), start_token, dtype=torch.long, device=device)
        
        # è‡ªå›å½’ç”Ÿæˆ
        with torch.no_grad():
            for _ in range(max_len - 1):
                # ç”Ÿæˆå› æœæ©ç 
                tgt_mask = generate_causal_mask(tgt.size(1)).to(device)
                
                # Decodeï¼ˆä¼ é€’src_maskå’Œtgt_maskï¼‰
                decoder_output = self.decode(tgt, encoder_output, src_mask, tgt_mask)
                
                # é¢„æµ‹ä¸‹ä¸€ä¸ªtoken
                next_token_logits = self.output_projection(decoder_output[:, -1, :])
                next_token = next_token_logits.argmax(dim=-1, keepdim=True)
                
                # æ·»åŠ åˆ°åºåˆ—
                tgt = torch.cat([tgt, next_token], dim=1)
                
                # å¦‚æœæ‰€æœ‰åºåˆ—éƒ½ç”Ÿæˆäº†ç»“æŸæ ‡è®°ï¼Œåœæ­¢
                if (next_token == end_token).all():
                    break
        
        return tgt


def visualize_model_structure():
    """å¯è§†åŒ– Transformer æ¨¡å‹ç»“æ„"""
    print("\n" + "="*60)
    print("Transformer æ¨¡å‹ç»“æ„")
    print("="*60)
    
    structure = """
    
    è¾“å…¥åºåˆ— (Source)              ç›®æ ‡åºåˆ— (Target)
         |                              |
         v                              v
    +----------+                  +----------+
    | Embedding|                  | Embedding|
    +----------+                  +----------+
         |                              |
         v                              v
    +----------+                  +----------+
    | Pos Enc  |                  | Pos Enc  |
    +----------+                  +----------+
         |                              |
         v                              |
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       |
    â”‚ Encoder  â”‚                       |
    â”‚  Block 1 â”‚                       |
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       |
         |                              |
         v                              |
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       |
    â”‚ Encoder  â”‚                       |
    â”‚  Block N â”‚                       |
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       |
         |                              |
         v                              v
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚   Decoder    â”‚
                        â”‚   Block 1    â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               |
                               v
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚   Decoder    â”‚
                        â”‚   Block N    â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               |
                               v
                        +--------------+
                        | Linear Layer |
                        +--------------+
                               |
                               v
                          è¾“å‡º (Output)
    
    æ¯ä¸ª Encoder Block:
      - Multi-Head Self-Attention
      - Add & Norm
      - Feed Forward Network
      - Add & Norm
    
    æ¯ä¸ª Decoder Block:
      - Masked Multi-Head Self-Attention
      - Add & Norm
      - Multi-Head Cross-Attention
      - Add & Norm
      - Feed Forward Network
      - Add & Norm
    """
    
    print(structure)


def test_transformer():
    """æµ‹è¯•å®Œæ•´çš„ Transformer æ¨¡å‹"""
    print("\n" + "="*50)
    print("æµ‹è¯•å®Œæ•´ Transformer æ¨¡å‹")
    print("="*50)
    
    # å‚æ•°é…ç½®
    src_vocab_size = 10000
    tgt_vocab_size = 10000
    d_model = 512
    num_heads = 8
    num_encoder_layers = 6
    num_decoder_layers = 6
    d_ff = 2048
    batch_size = 2
    src_len = 10
    tgt_len = 8
    
    print(f"\næ¨¡å‹é…ç½®:")
    print(f"  - æºè¯æ±‡è¡¨å¤§å°: {src_vocab_size}")
    print(f"  - ç›®æ ‡è¯æ±‡è¡¨å¤§å°: {tgt_vocab_size}")
    print(f"  - æ¨¡å‹ç»´åº¦: {d_model}")
    print(f"  - æ³¨æ„åŠ›å¤´æ•°: {num_heads}")
    print(f"  - Encoder å±‚æ•°: {num_encoder_layers}")
    print(f"  - Decoder å±‚æ•°: {num_decoder_layers}")
    print(f"  - å‰é¦ˆç½‘ç»œç»´åº¦: {d_ff}")
    
    # åˆ›å»ºæ¨¡å‹
    model = Transformer(
        src_vocab_size=src_vocab_size,
        tgt_vocab_size=tgt_vocab_size,
        d_model=d_model,
        num_heads=num_heads,
        num_encoder_layers=num_encoder_layers,
        num_decoder_layers=num_decoder_layers,
        d_ff=d_ff
    )
    model.eval()
    
    # åˆ›å»ºè¾“å…¥æ•°æ®
    src = torch.randint(0, src_vocab_size, (batch_size, src_len))
    tgt = torch.randint(0, tgt_vocab_size, (batch_size, tgt_len))
    
    print(f"\nè¾“å…¥:")
    print(f"  - æºåºåˆ—å½¢çŠ¶: {src.shape}")
    print(f"  - ç›®æ ‡åºåˆ—å½¢çŠ¶: {tgt.shape}")
    
    # ç”Ÿæˆæ©ç 
    tgt_mask = generate_causal_mask(tgt_len)
    
    # å‰å‘ä¼ æ’­
    with torch.no_grad():
        output = model(src, tgt, tgt_mask=tgt_mask)
    
    print(f"\nè¾“å‡º:")
    print(f"  - è¾“å‡ºå½¢çŠ¶: {output.shape}")
    print(f"  - é¢„æœŸå½¢çŠ¶: ({batch_size}, {tgt_len}, {tgt_vocab_size})")
    
    # éªŒè¯
    assert output.shape == (batch_size, tgt_len, tgt_vocab_size), "è¾“å‡ºå½¢çŠ¶ä¸åŒ¹é…ï¼"
    print("âœ… å½¢çŠ¶éªŒè¯é€šè¿‡")
    
    # æµ‹è¯•ç”ŸæˆåŠŸèƒ½
    print("\næµ‹è¯•è‡ªå›å½’ç”Ÿæˆ...")
    with torch.no_grad():
        generated = model.generate(src, max_len=15)
    print(f"ç”Ÿæˆåºåˆ—å½¢çŠ¶: {generated.shape}")
    print(f"ç”Ÿæˆçš„token: {generated[0, :10].tolist()}")
    print("âœ… ç”Ÿæˆæµ‹è¯•é€šè¿‡")
    
    # å‚æ•°ç»Ÿè®¡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"\næ¨¡å‹ç»Ÿè®¡:")
    print(f"  - æ€»å‚æ•°é‡: {total_params:,}")
    print(f"  - å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    print(f"  - æ¨¡å‹å¤§å°: {total_params * 4 / 1024 / 1024:.2f} MB (float32)")
    
    # å¯è§†åŒ–æ¨¡å‹ç»“æ„
    visualize_model_structure()
    
    print("\nâœ… Transformer æ¨¡å‹æµ‹è¯•å®Œæˆï¼\n")


if __name__ == "__main__":
    test_transformer()

